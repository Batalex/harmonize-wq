---
title: "R markdown for harmonize-wq Harmonize_Pensacola"
author: "Cristina Mullin"
date: '2022-08-31'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Harmonize_Pensacola R Markdown}
  %\usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

## R Markdown
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Standardize, clean and wrangle Water Quality Portal data in Pensacola and Perdido Bays into more analytic-ready formats using the harmonize_wq package
US EPAâ€™s Water Quality Portal (WQP) aggregates water quality, biological, and physical data provided by many organizations and has become an essential resource with tools to query and retrieval data using python or R. Given the variety of data and variety of data originators, using the data in analysis often requires data cleaning to ensure it meets the required quality standards and data wrangling to get it in a more analytic-ready format. Recognizing the definition of analysis-ready varies depending on the analysis, the harmonixe_wq package is intended to be a flexible water quality specific framework to help:

Identify differences in data units (including speciation and basis)
Identify differences in sampling or analytic methods
Resolve data errors using transparent assumptions
Reduce data to the columns that are most commonly needed
Transform data from long to wide format
Domain experts must decide what data meets their quality standards for data comparability and any thresholds for acceptance or rejection.

The first part of this notebook walks through a typical harmonization process on data retrieved from Perdido and Pensacola Bays, FL. The second part of the notebook takes a deeper dive into exactly what is done to each water quality characteristic result and some ways to leverage additional functions in the package for special use cases.

## Install R and Python dependencies
```{r, results = 'hide', message = FALSE, warning = FALSE}

install.packages("reticulate")
library(reticulate)

# If Conda is installed somewhere else you can specify it, e.g.,:
#options(reticulate.conda_binary = "~bin\\Python\\Scripts\\conda.exe")

conda_create("wq-reticulate")
conda_install("wq-reticulate", "geopandas")
conda_install("wq-reticulate", "pint")
conda_install("wq-reticulate", "dataretrieval")

# Only works with py install (pip), which defaults to vrtualenevs,
#envname may need to be the full path, e.g.: "~opt/anaconda3/envs/wq-reticulate"
py_install("git+https://github.com/USEPA/harmonize-wq.git", pip = TRUE, envname = "wq-reticulate")

use_condaenv("wq-reticulate")

# Use these reticulate imports to test the modules are installed
import("harmonize_wq")
import("dataretrieval")

```

## Simple example workflow for temperatures

dataretrieval Query for a geojson
```{python}

# Outside of a markdown file run python code w/ reticulate using:
#reticulate::repl_python()

import dataretrieval.wqp as wqp

#does not work
from harmonize_wq import wrangle

# File for area of interest
aoi_url = r'https://raw.githubusercontent.com/USEPA/harmonize-wq/main/harmonize_wq/tests/data/PPBays_NCCA.geojson'

# Build query and get data with dataretrieval
query = {'characteristicName': ['Temperature, water',
                                'Depth, Secchi disk depth',
                                ]}
#use harmonize-wq to wrangle
query['bBox'] = wrangle.get_bounding_box(aoi_url)
query['dataProfile'] = 'narrowResult'

# Run query
res_narrow, md_narrow = wqp.get_results(**query)

# dataframe of downloaded results
res_narrow
```

Harmonize and clean all results

```{python}
from harmonize_wq import harmonize
from harmonize_wq import clean

df_harmonized = harmonize.harmonize_all(res_narrow, errors='raise')
df_harmonized

# Clean up other columns of data
df_cleaned = clean.datetime(df_harmonized)  # datetime
df_cleaned = clean.harmonize_depth(df_cleaned)  # Sample depth
df_cleaned
```


##Transform results from long to wide format

There are many columns in the dataframe that are characteristic specific, that is they have different values for the same sample depending on the characteristic. To ensure one result for each sample after the transformation of the data these columns must either be split, generating a new column for each characteristic with values, or moved out from the table if not being used.

```{python}
from harmonize_wq import wrangle

# Split QA column into multiple characteristic specific QA columns
df_full = wrangle.split_col(df_cleaned)

# Divide table into columns of interest (main_df) and characteristic specific metadata (chars_df)
main_df, chars_df = wrangle.split_table(df_full)

# Combine rows with the same sample organization, activity, location, and datetime
df_wide = wrangle.collapse_results(main_df)

# Reduced columns
df_wide.columns
```

## Map results

```{python}
from harmonize_wq import location
from harmonize_wq import visualize

# Get harmonized stations clipped to the Area of Interest
stations_gdf, stations, site_md = location.get_harmonized_stations(query, aoi=aoi_url)

# Map average temperature results at each station
gdf_temperature = visualize.map_measure(df_wide, stations_gdf, 'Temperature')
gdf_temperature.plot(column='mean', cmap='OrRd', legend=True)
```

import the required libraries. Check requirements.txt for dependencies that should be installed.
```{python}
import os
import pandas
import geopandas
from harmonize_wq import harmonize
from harmonize_wq import convert
from harmonize_wq import wrangle
from harmonize_wq import clean
import dataretrieval.wqp as wqp
```

Download location data using dataretrieval
```{python}

```

