{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook walks through processing WQP data using the harmonize_wq package. It loads a larger set of Gulf of Mexico Esturaries, running on one at a time. It does not dig into report and nauances of results as much.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import the required libraries. Check requirements.txt for dependencies that should be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import geopandas\n",
    "from harmonize_wq import harmonize\n",
    "from harmonize_wq import convert\n",
    "from harmonize_wq import wrangle\n",
    "from harmonize_wq import clean\n",
    "import dataretrieval.wqp as wqp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download location data using dataretrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read geometry for Area of Interest from local file\n",
    "i = 1  #Index for the estuary to retrieve (UPDATE EACH TIME)\n",
    "\n",
    "# If saving results locally set file names for outputs\n",
    "out_dir = r'D:\\Local_GIS\\NCCA'  # UPDATE ONCE WITH TEMP DIRECTORY\n",
    "aoi_dir = os.path.join(out_dir, r'NCCA_2020_dissolvedon_EDACDA_NM.shp')\n",
    "aoi_gdf_all = geopandas.read_file(aoi_dir)\n",
    "\n",
    "# WGS 1984 for WQP query\n",
    "aoi_gdf_all = aoi_gdf_all.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the Gulf of Mexico Estuaries\n",
    "aoi_gdf_all.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reformated estuary name\n",
    "estuary_name = aoi_gdf_all.iloc[i]['EDACDA_NM']\n",
    "out_est_name = 'Estuary_' + str(estuary_name).replace(\" \", \"_\")\n",
    "out_est_name = out_est_name.replace(\".\", \"\")\n",
    "out_est_name = out_est_name.replace(\"(\", \"\")\n",
    "out_est_name = out_est_name.replace(\")\", \"\")\n",
    "print('Estuary Name: \"{}\" -> \"{}\"'.format(estuary_name, out_est_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get polygon from polygons\n",
    "aoi_gdf = aoi_gdf_all.loc[[i],'geometry']\n",
    "#aoi_gdf = aoi_gdf_all.iloc[i]['geometry']\n",
    "#aoi_gdf['geometry'] = geopandas.GeoDataFrame(aoi_gdf, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry for selection\n",
    "aoi_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial query parameters\n",
    "# Each estuary may be multi-polygon, so the query will be built around the full extent\n",
    "#instead of one since polygon\n",
    "bBox = ','.join(map(str, aoi_gdf.total_bounds))  #get bBox string for total extent of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query\n",
    "query = {'characteristicName': ['Phosphorus',\n",
    "                                'Temperature, water',\n",
    "                                'Depth, Secchi disk depth',\n",
    "                                'Dissolved oxygen (DO)',\n",
    "                                'Salinity',\n",
    "                                'pH',\n",
    "                                'Nitrogen',\n",
    "                                'Conductivity',\n",
    "                                'Organic carbon',\n",
    "                                'Chlorophyll a',\n",
    "                                'Turbidity',\n",
    "                                'Sediment',\n",
    "                                'Fecal Coliform',\n",
    "                                'Escherichia coli']}\n",
    "query['bBox'] = bBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query stations (can be slow)\n",
    "stations, site_md = wqp.what_sites(**query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize location datums to 4326\n",
    "stations_gdf = harmonize.harmonize_locations(stations, outEPSG=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip it to area of interest\n",
    "stations_clipped = geopandas.clip(stations_gdf, aoi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it\n",
    "out_geo = os.path.join(out_dir, out_est_name + \".shp\")\n",
    "#stations_clipped.to_file(out_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map it\n",
    "stations_clipped.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harmonize characteristic data (all at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query results\n",
    "query['dataProfile'] = 'narrowResult'\n",
    "res_narrow, md_narrow = wqp.get_results(**query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res_narrow\n",
    "# Save it\n",
    "out_df = os.path.join(out_dir, out_est_name + \".csv\")\n",
    "df.to_csv(out_df,index=False)\n",
    "# Look at it\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The harmonize_all() function identifies the characteristics present and uses preset defaults to harmonize each. This function does not has as much flexibility e.g., to keep intermediate columns, produce reports, or convert to non-default units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Harmonize all\n",
    "# Note that errors='skip' or 'ignore' will be needed to supress errors in dimensionality in some cases\n",
    "# such errors occur when a unit can not be converted to the desired unit (e.g., degC to m)\n",
    "df = harmonize.harmonize_all(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set standard columns to look through results\n",
    "cols = ['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode', 'QA_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if there were no results for a given characteristic a result column will not be generated for that characteristic and there will be a keyError when trying to look at results, e.g., 'KeyError: \"['Conductivity'] not in index\"' if there are no conductivity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secchi\n",
    "df.loc[df['CharacteristicName']=='Depth, Secchi disk depth', cols + ['Secchi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "df.loc[df['CharacteristicName']=='Temperature, water', cols + ['Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolved Oxygen\n",
    "df.loc[df['CharacteristicName']=='Dissolved oxygen (DO)', cols + ['DO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pH\n",
    "df.loc[df['CharacteristicName']=='pH', cols + ['pH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salinity\n",
    "df.loc[df['CharacteristicName']=='Salinity', cols + ['Salinity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nitrogen\n",
    "df.loc[df['CharacteristicName']=='Nitrogen', cols + ['Nitrogen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conductivity\n",
    "df.loc[df['CharacteristicName']=='Conductivity', cols + ['Conductivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chlorophyll A\n",
    "df.loc[df['CharacteristicName']=='Chlorophyll a', cols + ['Chlorophyll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon\n",
    "df.loc[df['CharacteristicName']=='Organic carbon', cols + ['Carbon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turbidity\n",
    "df.loc[df['CharacteristicName']=='Turbidity', cols + ['Turbidity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sediment\n",
    "df.loc[df['CharacteristicName']=='Sediment', cols + ['Sediment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Phosphorus\n",
    "df.loc[df['TDP_Phosphorus'].notna(), ['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode', 'QA_flag', 'TDP_Phosphorus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['TP_Phosphorus'].notna(), ['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode', 'QA_flag', 'TP_Phosphorus']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Salinity and Conductivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the number of results and variability in outliers is so variable across individual estuaries this functionality is not demonstrated here. Look to the other notebook examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datetime() formats time using dataretrieval and ActivityStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First inspect the existing unformated fields\n",
    "cols = ['ActivityStartDate', 'ActivityStartTime/Time', 'ActivityStartTime/TimeZoneCode']\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the input columns are dropped (rename the result to preserve these columns)\n",
    "df = clean.datetime(df)\n",
    "df[['StartDate', 'Activity_datetime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity_datetime combines all three time component columns into UTC. If time is missing this is NaT so a startDate column is used to preserve date only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth of sample (default units='meter')\n",
    "df = clean.harmonize_depth(df)\n",
    "#df.loc[df['ResultDepthHeightMeasure/MeasureValue'].dropna(), \"Depth\"]\n",
    "df['ResultDepthHeightMeasure/MeasureValue'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Data are often lacking sample depth metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristic to Column (long to wide format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split single QA column into multiple by characteristic (rename the result to preserve these QA_flags)\n",
    "df2 = wrangle.split_col(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This expands the single col (QA_flag) out to a number of new columns based on the unique characteristicNames and speciation\n",
    "print('{} new columns'.format(len(df2.columns) - len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: there are fewer rows because NAN results are also dropped in this step\n",
    "print('{} fewer rows'.format(len(df)-len(df2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine Carbon flags from earlier in notebook (note these are empty now because NAN is dropped)\n",
    "cols = ['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode', 'Carbon', 'QA_Carbon']\n",
    "df2.loc[df2['QA_Carbon'].notna(), cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the table is divided into the columns of interest (main_df) and characteristic specific metadata (chars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split table into main and characteristics tables\n",
    "main_df, chars_df = wrangle.split_table(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns still in main table\n",
    "main_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at main table results (first 5)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty columns that could be dropped (Mostly QA columns)\n",
    "cols = list(main_df.columns)\n",
    "x = main_df.dropna(axis=1, how='all')\n",
    "[col for col in cols if col not in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to stations to quickly aggegate/map\n",
    "merge_cols = ['MonitoringLocationIdentifier', 'OrganizationIdentifier']\n",
    "gdf_cols = ['geometry', 'QA_flag']\n",
    "results_df = wrangle.merge_tables(main_df, stations_clipped, gdf_cols, merge_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map average temperature\n",
    "results_gdf = geopandas.GeoDataFrame(results_df, geometry='geometry')\n",
    "results_gdf.plot(column='Temperature', cmap='OrRd')"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "5.0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
